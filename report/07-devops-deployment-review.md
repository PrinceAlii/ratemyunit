# DevOps Deployment Review - RateMyUnit AWS Infrastructure

**Reviewer:** Senior DevOps/SRE Engineer
**Date:** January 29, 2026
**Documents Reviewed:**
- `conductor/aws-deployment-plan.md`
- `conductor/production-readiness.md`

**Cross-Referenced Reports:**
- `report/02-architecture-review.md`
- `report/03-security-audit.md`
- `report/04-performance-analysis.md`
- `report/06-bug-detection-report.md`

---

## Executive Assessment

**Deployment Plan Grade: C+ (72/100)**
**Production Readiness Grade: B- (70/100)**
**Overall DevOps Maturity: Level 2/5** (Managed, not yet Defined/Optimized)

### Critical Findings

üî¥ **BLOCKERS (Must fix before production):**
1. Browser memory leak (BUG-CRITICAL-001) not addressed in deployment plan
2. Database coupling in scrapers breaks testability and deployment isolation
3. Race condition in browser singleton will cause crashes under load
4. No disaster recovery or backup restoration procedures documented
5. Missing monitoring, alerting, and incident response procedures

‚ö†Ô∏è **HIGH PRIORITY (Fix within Week 1):**
1. Zero-downtime deployment strategy undefined
2. Security vulnerabilities (ReDoS, XXE) from security audit not mentioned
3. No load testing or capacity planning before production
4. Graceful shutdown handling missing (SIGTERM, connection draining)
5. Database migration rollback strategy not defined

---

## AWS Deployment Plan Review

### ‚úÖ Strengths

1. **Cost Optimization (Excellent)**
   - Proper use of AWS Free Tier limits
   - Smart separation: Static assets ‚Üí S3/CloudFront, API ‚Üí EC2
   - Cloudflare for free SSL/DDoS instead of paid AWS services
   - Correct instance sizing (t3.micro for both EC2 and RDS)

2. **Network Security (Good)**
   - Private subnets for RDS ‚úÖ
   - Security groups properly scoped (DB only accessible from EC2) ‚úÖ
   - Cloudflare IP whitelisting mentioned ‚úÖ

3. **Infrastructure as Code (Good Foundation)**
   - Terraform with S3 backend and DynamoDB locking ‚úÖ
   - Proper VPC/subnet architecture ‚úÖ

### ‚ùå Critical Issues

#### CRITICAL-1: Single Point of Failure (SPOF)

**Location:** Architecture diagram, EC2 section

**Issue:**
```
Single EC2 t3.micro running:
‚îú‚îÄ API server (Node.js)
‚îú‚îÄ Redis (Docker container)
‚îî‚îÄ Playwright browser pool

If this instance fails:
- 100% downtime
- No automatic recovery
- Manual intervention required
```

**Impact:**
- **MTTR (Mean Time To Recovery):** 15-60 minutes (manual SSH, docker restart)
- **RPO (Recovery Point Objective):** Undefined - no mention of EC2 backup strategy
- **RTO (Recovery Time Objective):** Undefined

**Remediation:**
```hcl
# Add to Terraform
resource "aws_launch_template" "api" {
  # ... instance config

  monitoring {
    enabled = true
  }

  user_data = base64encode(templatefile("user-data.sh", {
    enable_cloudwatch_agent = true
  }))
}

resource "aws_autoscaling_group" "api" {
  min_size         = 1
  max_size         = 1
  desired_capacity = 1

  health_check_type         = "ELB"
  health_check_grace_period = 300

  # Auto-replace unhealthy instances
  force_delete = true
}

resource "aws_cloudwatch_metric_alarm" "instance_health" {
  alarm_name          = "ec2-instance-health"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = 2
  metric_name         = "StatusCheckFailed"
  namespace           = "AWS/EC2"
  period              = 60
  statistic           = "Average"
  threshold           = 1

  alarm_actions = [aws_autoscaling_policy.replace_instance.arn]
}
```

**Estimated Effort:** 8-12 hours

---

#### CRITICAL-2: Browser Memory Leak Unaddressed

**Cross-Reference:** `report/06-bug-detection-report.md` BUG-CRITICAL-001

**Issue:** The deployment plan deploys code with a known critical browser memory leak:

```typescript
// Current code in queue.ts
let browserInstance: any = null;  // ‚ùå Leaks 50-100MB per leaked page
let jobCount = 0;
const MAX_JOBS_PER_BROWSER = 100;  // Arbitrary limit
```

**Production Impact:**
```
EC2 t3.micro specs:
- RAM: 1GB total
- OS overhead: ~200MB
- Node.js baseline: ~100MB
- Redis container: ~50MB
- Available for browser: ~650MB

Browser memory usage:
- Base: 100-200MB
- Per leaked page: 50-100MB
- After 10 leaked pages: 500MB-1GB leaked
- Result: OOM crash, service down
```

**Remediation Priority:** **BLOCKER** - Must fix before production deployment

**Fix Required:** Implement connection pooling with `generic-pool`:
```typescript
import { createPool } from 'generic-pool';

const browserPool = createPool({
  create: async () => {
    const browser = await chromium.launch({ headless: true });
    return browser;
  },
  destroy: async (browser) => {
    await browser.close();
  },
  validate: async (browser) => {
    return browser.isConnected();
  },
}, {
  max: 2,              // Max 2 browsers on t3.micro
  min: 1,              // Keep 1 warm
  idleTimeoutMillis: 30000,
  acquireTimeoutMillis: 30000,
});
```

**Estimated Effort:** 12-16 hours

---

#### CRITICAL-3: No Monitoring or Alerting Strategy

**Location:** Entire deployment plan

**Issue:** Zero mention of:
- CloudWatch alarms
- Log aggregation
- Metric collection
- On-call alerting
- Incident response

**Real-World Scenario:**
```
3:00 AM: Browser memory leak causes OOM
         ‚Üí EC2 instance freezes
         ‚Üí No alerts sent
         ‚Üí Users see 502 errors
8:00 AM: First developer checks phone
         ‚Üí Notices downtime on Twitter
         ‚Üí Logs in to AWS Console
         ‚Üí Restarts instance
Result: 5 hours of downtime, unknown data loss
```

**Minimum Required Alarms:**

```hcl
# CloudWatch Alarms (Terraform)
resource "aws_cloudwatch_metric_alarm" "cpu_high" {
  alarm_name          = "api-cpu-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = 300
  statistic           = "Average"
  threshold           = 80
  alarm_description   = "CPU > 80% for 10 minutes"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}

resource "aws_cloudwatch_metric_alarm" "memory_high" {
  alarm_name          = "api-memory-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "mem_used_percent"
  namespace           = "CWAgent"
  period              = 300
  statistic           = "Average"
  threshold           = 85
  alarm_description   = "Memory > 85% for 10 minutes"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}

resource "aws_cloudwatch_metric_alarm" "status_check_failed" {
  alarm_name          = "ec2-status-check-failed"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "StatusCheckFailed"
  namespace           = "AWS/EC2"
  period              = 60
  statistic           = "Average"
  threshold           = 0
  alarm_description   = "EC2 instance health check failed"
  alarm_actions       = [aws_sns_topic.critical_alerts.arn]
}

resource "aws_cloudwatch_metric_alarm" "rds_cpu_high" {
  alarm_name          = "rds-cpu-high"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "CPUUtilization"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 80
  dimensions = {
    DBInstanceIdentifier = aws_db_instance.postgres.id
  }
  alarm_actions = [aws_sns_topic.alerts.arn]
}

resource "aws_cloudwatch_metric_alarm" "rds_storage_low" {
  alarm_name          = "rds-storage-low"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = 1
  metric_name         = "FreeStorageSpace"
  namespace           = "AWS/RDS"
  period              = 300
  statistic           = "Average"
  threshold           = 2147483648  # 2GB
  dimensions = {
    DBInstanceIdentifier = aws_db_instance.postgres.id
  }
  alarm_actions = [aws_sns_topic.critical_alerts.arn]
}

resource "aws_sns_topic" "alerts" {
  name = "ratemyunit-alerts"
}

resource "aws_sns_topic_subscription" "email" {
  topic_arn = aws_sns_topic.alerts.arn
  protocol  = "email"
  endpoint  = "devops@ratemyunit.com"
}
```

**Estimated Effort:** 4-6 hours

---

#### CRITICAL-4: No Backup or Disaster Recovery Plan

**Location:** Missing from both documents

**Issue:**
- RDS automated backups not mentioned
- No backup retention policy defined
- No disaster recovery runbook
- No backup restoration testing

**Current Risk:**
```
Scenario: Accidental DELETE query in production
- No backup restoration procedure documented
- No tested backup restoration
- RPO: Unknown (likely 24 hours if using RDS defaults)
- RTO: Unknown (manual restoration, 1-4 hours?)
```

**Minimum Required:**

```hcl
# RDS Backups (Terraform)
resource "aws_db_instance" "postgres" {
  # ... existing config

  backup_retention_period = 7  # 7 days (free tier: 1-7 days)
  backup_window          = "03:00-04:00"  # UTC
  maintenance_window     = "sun:04:00-sun:05:00"

  copy_tags_to_snapshot  = true
  skip_final_snapshot    = false
  final_snapshot_identifier = "ratemyunit-final-snapshot-${timestamp()}"

  enabled_cloudwatch_logs_exports = ["postgresql", "upgrade"]
}

# EC2 AMI Backups
resource "aws_dlm_lifecycle_policy" "ec2_snapshots" {
  description        = "EC2 AMI backup policy"
  execution_role_arn = aws_iam_role.dlm_lifecycle_role.arn
  state              = "ENABLED"

  policy_details {
    resource_types = ["INSTANCE"]

    schedule {
      name = "Daily snapshots"

      create_rule {
        interval      = 24
        interval_unit = "HOURS"
        times         = ["03:00"]
      }

      retain_rule {
        count = 7  # Keep 7 daily snapshots
      }

      tags_to_add = {
        SnapshotType = "DailyBackup"
      }
    }

    target_tags = {
      Name = "ratemyunit-api"
    }
  }
}
```

**Disaster Recovery Runbook Required:**
1. RDS point-in-time recovery procedure
2. EC2 instance restoration from AMI
3. Database restore testing (quarterly)
4. Failover testing checklist

**Estimated Effort:** 8-10 hours

---

#### HIGH-1: Zero-Downtime Deployment Missing

**Location:** Deployment Steps section

**Current Deployment Process:**
```bash
# Step 4 (from plan):
SSH to EC2
docker pull
docker-compose up  # ‚ùå This STOPS the current container first!
```

**Impact:**
- **Downtime per deployment:** 30-120 seconds
- **User experience:** 502 errors during deployment
- **Frequency:** Every code push (could be multiple times per week)

**Remediation - Blue/Green Deployment:**

```yaml
# docker-compose.yml (Enhanced)
version: '3.8'
services:
  api-blue:
    image: ${API_IMAGE}:${VERSION}
    container_name: api-blue
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  api-green:
    image: ${API_IMAGE}:${VERSION}
    container_name: api-green
    ports:
      - "3001:3000"
    environment:
      - NODE_ENV=production
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api-blue
```

```bash
#!/bin/bash
# deploy.sh - Zero-downtime deployment script

ACTIVE_COLOR=$(curl -s http://localhost/color)
INACTIVE_COLOR="green"

if [ "$ACTIVE_COLOR" == "blue" ]; then
  INACTIVE_COLOR="green"
  INACTIVE_PORT=3001
else
  INACTIVE_COLOR="blue"
  INACTIVE_PORT=3000
fi

echo "Active: $ACTIVE_COLOR, Deploying to: $INACTIVE_COLOR"

# 1. Pull new image
docker pull ${API_IMAGE}:${VERSION}

# 2. Start inactive container with new code
docker-compose up -d api-$INACTIVE_COLOR

# 3. Wait for health check
echo "Waiting for health check..."
for i in {1..30}; do
  if curl -f http://localhost:$INACTIVE_PORT/health; then
    echo "Health check passed!"
    break
  fi
  sleep 2
done

# 4. Switch traffic to new container (update nginx upstream)
sed -i "s/api-$ACTIVE_COLOR/api-$INACTIVE_COLOR/" nginx.conf
nginx -s reload

# 5. Wait for active connections to drain
sleep 10

# 6. Stop old container
docker-compose stop api-$ACTIVE_COLOR

echo "Deployment complete! Traffic now on $INACTIVE_COLOR"
```

**Alternative (Simpler):** Use rolling restart with health checks:
```bash
# deploy-simple.sh
docker-compose pull
docker-compose up -d --no-deps --build api
# Docker will start new container, wait for health check, then stop old one
```

**Estimated Effort:** 6-8 hours

---

#### HIGH-2: Security Vulnerabilities Not Cross-Referenced

**Location:** Production Readiness Checklist

**Issue:** Security audit identified critical vulnerabilities that are **not mentioned** in production readiness:

**From `report/03-security-audit.md`:**
1. **CRITICAL: ReDoS Injection** in regex pattern validation
2. **CRITICAL: XXE Attack** in XML sitemap parsing
3. **HIGH: Missing rate limiting** on public endpoints
4. **HIGH: User enumeration** via timing attacks

**Missing from Production Checklist:**
- [ ] Fix ReDoS vulnerability in `template.ts:206-252`
- [ ] Replace regex parser with safe XML parser (fast-xml-parser)
- [ ] Implement Redis-based rate limiting (not just memory)
- [ ] Add constant-time comparison for auth checks
- [ ] Security headers (CSP, HSTS, X-Frame-Options) - mentioned but not detailed

**Remediation Required Before Production:**

```typescript
// 1. Fix ReDoS (template.ts)
// BEFORE:
const regex = new RegExp(pattern);  // ‚ùå User-controlled regex

// AFTER:
import { safeParse } from 'safe-regex2';
if (!safeParse(pattern)) {
  throw new Error('Regex pattern is unsafe (potential ReDoS)');
}
const regex = new RegExp(pattern);
```

```typescript
// 2. Fix XXE (courseloop.ts)
// BEFORE:
const locMatches = xmlContent.matchAll(/<loc>(.*?)<\/loc>/g);  // ‚ùå Regex on XML

// AFTER:
import { XMLParser } from 'fast-xml-parser';
const parser = new XMLParser({
  ignoreAttributes: false,
  parseTagValue: false,
  processEntities: false,  // Prevent XXE
});
const parsed = parser.parse(xmlContent);
```

```typescript
// 3. Redis-based Rate Limiting (app.ts)
// BEFORE:
rateLimit({ windowMs: 60000, max: 100 })  // ‚ùå In-memory only

// AFTER:
import rateLimit from 'express-rate-limit';
import RedisStore from 'rate-limit-redis';
import { createClient } from 'redis';

const redisClient = createClient({ url: process.env.REDIS_URL });
await redisClient.connect();

app.use('/api/public', rateLimit({
  windowMs: 60000,
  max: 100,
  store: new RedisStore({
    client: redisClient,
    prefix: 'rl:',
  }),
}));
```

**Estimated Effort:** 12-16 hours

---

### ‚ö†Ô∏è High Priority Issues

#### HIGH-3: User Data Script Lacks Idempotency

**Location:** Compute (EC2) checklist

**Current Plan:**
```bash
# User Data Script (mentioned):
- [ ] Install Docker & Docker Compose
- [ ] Login to ECR/GHCR
- [ ] Pull latest image
- [ ] Run docker-compose up
```

**Issue:** User data runs **every time** the instance starts (not just first boot)

**Impact:**
- Package reinstallation on every reboot (slow startup)
- Potential race conditions if Docker containers start during package updates
- No logging of user data execution

**Best Practice User Data Script:**

```bash
#!/bin/bash
set -e  # Exit on error
exec > >(tee /var/log/user-data.log)  # Log everything
exec 2>&1

# Only run on first boot
if [ -f /var/lib/cloud/instance/deployed ]; then
  echo "User data already executed, skipping..."
  exit 0
fi

echo "Starting user data script..."

# Update system
yum update -y

# Install Docker
if ! command -v docker &> /dev/null; then
  yum install -y docker
  systemctl enable docker
  systemctl start docker
fi

# Install Docker Compose
if ! command -v docker-compose &> /dev/null; then
  curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
  chmod +x /usr/local/bin/docker-compose
fi

# Install CloudWatch Agent
wget https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
rpm -U ./amazon-cloudwatch-agent.rpm

# Configure CloudWatch Agent
cat > /opt/aws/amazon-cloudwatch-agent/etc/config.json <<EOF
{
  "metrics": {
    "namespace": "RateMyUnit/API",
    "metrics_collected": {
      "mem": {
        "measurement": [{"name": "mem_used_percent"}],
        "metrics_collection_interval": 60
      },
      "disk": {
        "measurement": [{"name": "disk_used_percent"}],
        "metrics_collection_interval": 60
      }
    }
  },
  "logs": {
    "logs_collected": {
      "files": {
        "collect_list": [
          {
            "file_path": "/var/log/docker-compose.log",
            "log_group_name": "/aws/ec2/ratemyunit/api",
            "log_stream_name": "{instance_id}"
          }
        ]
      }
    }
  }
}
EOF

/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \
  -a fetch-config \
  -m ec2 \
  -s \
  -c file:/opt/aws/amazon-cloudwatch-agent/etc/config.json

# Fetch secrets from SSM
export DB_HOST=$(aws ssm get-parameter --name /ratemyunit/db/host --query 'Parameter.Value' --output text --region us-east-1)
export DB_PASSWORD=$(aws ssm get-parameter --name /ratemyunit/db/password --with-decryption --query 'Parameter.Value' --output text --region us-east-1)

# Create docker-compose.yml with secrets
cat > /opt/ratemyunit/docker-compose.yml <<EOF
version: '3.8'
services:
  api:
    image: ${ECR_REPO_URL}:latest
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://\${DB_USER}:\${DB_PASSWORD}@\${DB_HOST}:5432/ratemyunit
      - REDIS_URL=redis://localhost:6379
    depends_on:
      - redis
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

volumes:
  redis-data:
EOF

# Start services
cd /opt/ratemyunit
docker-compose up -d

# Mark as deployed
touch /var/lib/cloud/instance/deployed
echo "User data script completed successfully"
```

**Estimated Effort:** 4-6 hours

---

#### HIGH-4: Graceful Shutdown Missing

**Location:** Production Readiness - Missing

**Issue:** No mention of handling SIGTERM/SIGINT signals for graceful shutdown

**Current Behavior:**
```
docker-compose stop
  ‚Üí Sends SIGTERM to Node.js process
  ‚Üí Node.js doesn't handle SIGTERM (default behavior)
  ‚Üí Docker waits 10 seconds
  ‚Üí Docker sends SIGKILL (forced termination)
  ‚Üí Active requests aborted mid-flight
  ‚Üí Database connections dropped without cleanup
```

**Impact:**
- Failed requests during deployment
- Potential database connection leaks
- Corrupted jobs in BullMQ queue

**Required Implementation:**

```typescript
// apps/api/src/index.ts
let server: ReturnType<typeof app.listen>;

const gracefulShutdown = async (signal: string) => {
  console.log(`${signal} received, starting graceful shutdown...`);

  // 1. Stop accepting new requests
  server.close(async (err) => {
    if (err) {
      console.error('Error closing HTTP server:', err);
      process.exit(1);
    }

    console.log('HTTP server closed, cleaning up resources...');

    try {
      // 2. Stop queue workers
      await scraperQueue.close();
      console.log('Queue workers stopped');

      // 3. Close database connections
      await db.$client.end();
      console.log('Database connections closed');

      // 4. Close Redis connection
      await redis.quit();
      console.log('Redis connection closed');

      // 5. Close browser instance
      if (browserInstance) {
        await browserInstance.close();
        console.log('Browser instance closed');
      }

      console.log('Graceful shutdown complete');
      process.exit(0);
    } catch (error) {
      console.error('Error during graceful shutdown:', error);
      process.exit(1);
    }
  });

  // Force shutdown after 30 seconds
  setTimeout(() => {
    console.error('Graceful shutdown timeout, forcing exit...');
    process.exit(1);
  }, 30000);
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

// Start server
const PORT = process.env.PORT || 3000;
server = app.listen(PORT, () => {
  console.log(`Server listening on port ${PORT}`);
});
```

```yaml
# docker-compose.yml
services:
  api:
    # ... other config
    stop_grace_period: 45s  # Allow 45s for graceful shutdown
```

**Estimated Effort:** 4-6 hours

---

#### HIGH-5: Database Migration Strategy Incomplete

**Location:** Production Readiness, Database section

**Current Plan:**
```
- [ ] Migration Strategy: Ensure drizzle-kit migrate runs automatically
      on container startup before the app accepts traffic.
```

**Issues:**
1. No rollback strategy for failed migrations
2. No migration testing in staging environment
3. No backward compatibility requirements
4. No mention of zero-downtime migration patterns

**Production Migration Risks:**

```
Scenario: Breaking schema change deployed

1. New code deployed with migration
2. Migration runs: ALTER TABLE units DROP COLUMN sessions;
3. Old code still running for 30s (blue-green overlap)
4. Old code queries sessions column
5. Result: 500 errors, production down
```

**Best Practices Required:**

1. **Backward Compatible Migrations:**
```typescript
// BAD: Breaking change
await db.schema.alterTable('units', (table) => {
  table.dropColumn('sessions');  // ‚ùå Old code breaks
});

// GOOD: Multi-phase migration
// Phase 1 (Deploy 1): Add new column
await db.schema.alterTable('units', (table) => {
  table.text('sessions_jsonb').nullable();
});

// Phase 2 (Deploy 2): Migrate data
await db.execute(sql`
  UPDATE units
  SET sessions_jsonb = sessions::jsonb
  WHERE sessions_jsonb IS NULL
`);

// Phase 3 (Deploy 3): Make non-nullable
await db.schema.alterTable('units', (table) => {
  table.text('sessions_jsonb').notNullable().alter();
});

// Phase 4 (Deploy 4): Drop old column
await db.schema.alterTable('units', (table) => {
  table.dropColumn('sessions');
});
```

2. **Migration Rollback Script:**
```bash
#!/bin/bash
# rollback-migration.sh

CURRENT_VERSION=$(psql $DATABASE_URL -t -c "SELECT version FROM drizzle_migrations ORDER BY created_at DESC LIMIT 1")
echo "Current migration version: $CURRENT_VERSION"

# Restore from RDS snapshot
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance-identifier ratemyunit-prod \
  --target-db-instance-identifier ratemyunit-prod-rollback \
  --restore-time $(date -u -d '5 minutes ago' +%Y-%m-%dT%H:%M:%SZ)

# Wait for restore
aws rds wait db-instance-available --db-instance-identifier ratemyunit-prod-rollback

# Switch connection string (requires downtime)
echo "Database restored to 5 minutes ago"
```

3. **Migration Testing Checklist:**
```markdown
## Pre-Production Migration Checklist

- [ ] Migration tested in local environment
- [ ] Migration tested in staging environment with production-like data
- [ ] Rollback procedure documented and tested
- [ ] Migration is backward compatible (old code won't break)
- [ ] Migration runs in <30 seconds (or split into smaller migrations)
- [ ] Database backup taken before migration
- [ ] Monitoring dashboard open during migration
- [ ] On-call engineer available during deployment window
```

**Estimated Effort:** 6-8 hours

---

## Production Readiness Review

### ‚úÖ Strengths

1. **Secret Management (Excellent)**
   - SSM Parameter Store integration planned ‚úÖ
   - Removal of `.env` files for production ‚úÖ

2. **Container Security (Good)**
   - Non-root user in Dockerfile ‚úÖ
   - Multi-stage builds for size optimization ‚úÖ
   - Image scanning with Trivy/Docker Scout ‚úÖ

3. **Logging (Good)**
   - Structured logging with pino ‚úÖ
   - JSON output in production ‚úÖ
   - Sensitive data redaction ‚úÖ

### ‚ùå Critical Gaps

#### MISSING-1: Load Testing & Capacity Planning

**Location:** Entire production readiness document

**Issue:** No mention of:
- Load testing requirements
- Expected traffic volume
- Capacity planning
- Performance benchmarks

**Risk:** Deploying to production with **unknown capacity limits**

**Required Load Tests:**

```javascript
// k6 load test script (load-test.js)
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 50 },   // Ramp up to 50 users
    { duration: '5m', target: 50 },   // Stay at 50 users
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 0 },    // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'],  // 95% of requests under 500ms
    http_req_failed: ['rate<0.01'],    // Error rate < 1%
  },
};

export default function() {
  // Test search endpoint
  const searchRes = http.get('https://api.ratemyunit.com/api/units?search=computer');
  check(searchRes, {
    'search status 200': (r) => r.status === 200,
    'search duration < 500ms': (r) => r.timings.duration < 500,
  });

  // Test unit detail endpoint
  const unitRes = http.get('https://api.ratemyunit.com/api/units/some-unit-id');
  check(unitRes, {
    'unit status 200': (r) => r.status === 200,
  });

  sleep(1);
}
```

**Capacity Planning Table:**

| Metric | Target | Current Estimate | Gap |
|--------|--------|------------------|-----|
| Concurrent Users | 100 | Unknown | ‚ö†Ô∏è Test Required |
| Requests/Second | 50 | Unknown | ‚ö†Ô∏è Test Required |
| p95 Latency (Search) | <500ms | Unknown | ‚ö†Ô∏è Test Required |
| p95 Latency (Scrape) | <60s | ~45s | ‚úÖ |
| Database Connections | 80 max (t3.micro) | ~20 | ‚úÖ |
| Memory Usage (EC2) | <800MB | ~650MB | ‚ö†Ô∏è Close |
| Scrape Queue Throughput | 10 jobs/min | ~8 jobs/min | ‚úÖ |

**Estimated Effort:** 8-12 hours (setup + testing + analysis)

---

#### MISSING-2: Incident Response Procedures

**Location:** Entire production readiness document

**Issue:** No incident response plan, runbooks, or escalation procedures

**Required Documentation:**

```markdown
# Incident Response Runbook

## Severity Levels

### SEV-1 (Critical) - Full Outage
- **Response Time:** 15 minutes
- **Escalation:** Immediately page on-call engineer
- **Examples:** Database down, EC2 instance crashed, 100% error rate

### SEV-2 (High) - Partial Outage
- **Response Time:** 1 hour
- **Escalation:** Slack notification to dev team
- **Examples:** Scraper queue stalled, high error rate (>5%)

### SEV-3 (Medium) - Degraded Performance
- **Response Time:** 4 hours
- **Escalation:** Email notification
- **Examples:** Slow queries, high latency

## Common Incidents

### Incident: EC2 Instance Unresponsive

**Symptoms:**
- 502 Bad Gateway errors
- Health check failing
- No response from API

**Diagnosis:**
1. Check EC2 instance status in AWS Console
2. Check CloudWatch CPU/Memory metrics
3. SSH to instance (or use Session Manager)
4. Check Docker container status: `docker ps`
5. Check logs: `docker-compose logs -f api`

**Resolution:**
1. If OOM: Restart Docker container: `docker-compose restart api`
2. If instance frozen: Reboot instance via AWS Console
3. If recurring: Increase instance size or fix memory leak

**Estimated Recovery Time:** 5-15 minutes

---

### Incident: Database Connection Exhaustion

**Symptoms:**
- Errors: "too many connections"
- API timeouts
- Slow queries

**Diagnosis:**
1. Check RDS connection count:
   ```sql
   SELECT count(*) FROM pg_stat_activity;
   ```
2. Check for long-running queries:
   ```sql
   SELECT pid, now() - query_start AS duration, query
   FROM pg_stat_activity
   WHERE state = 'active'
   ORDER BY duration DESC;
   ```

**Resolution:**
1. Kill long-running queries:
   ```sql
   SELECT pg_terminate_backend(pid) WHERE ...;
   ```
2. Restart API containers to reset connections
3. Investigate connection leak in code

**Estimated Recovery Time:** 10-30 minutes

---

### Incident: Scraper Queue Stalled

**Symptoms:**
- Queue has jobs but none processing
- Browser errors in logs

**Diagnosis:**
1. Check Redis: `redis-cli PING`
2. Check queue status: `GET /api/admin/queue/status`
3. Check browser logs in Docker

**Resolution:**
1. Pause queue: `POST /api/admin/queue/pause`
2. Restart API container
3. Resume queue: `POST /api/admin/queue/resume`

**Estimated Recovery Time:** 5-10 minutes
```

**Estimated Effort:** 12-16 hours

---

#### MISSING-3: Performance Budgets & SLOs

**Location:** Missing from production readiness

**Issue:** No Service Level Objectives (SLOs) or performance budgets defined

**Required SLO Definition:**

```yaml
# slo.yaml - Service Level Objectives
service: ratemyunit-api
slos:
  - name: API Availability
    target: 99.5%  # ~3.6 hours downtime/month
    measurement: (successful_requests / total_requests) * 100
    window: 30d

  - name: Search Latency (p95)
    target: 500ms
    measurement: p95(search_request_duration)
    window: 7d

  - name: Error Rate
    target: <1%
    measurement: (error_5xx / total_requests) * 100
    window: 1h

  - name: Scraper Success Rate
    target: >80%
    measurement: (successful_scrapes / total_scrapes) * 100
    window: 24h
```

**Performance Budget:**

| Resource | Budget | Current | Status |
|----------|--------|---------|--------|
| Homepage Bundle Size | <500KB | Unknown | ‚ö†Ô∏è |
| API Response Time (p95) | <500ms | Unknown | ‚ö†Ô∏è |
| Time to Interactive (TTI) | <3s | Unknown | ‚ö†Ô∏è |
| Largest Contentful Paint (LCP) | <2.5s | Unknown | ‚ö†Ô∏è |

**Estimated Effort:** 4-6 hours

---

## CI/CD Pipeline Review

### Current Plan Analysis

**From Production Readiness:**
```
- [ ] Build: Build API and Web
- [ ] Test: Run Unit (vitest) and E2E tests
- [ ] Lint: Run eslint and tsc
- [ ] Publish: Build Docker image and push to ECR
- [ ] Deploy: Trigger Terraform apply or SSH command to EC2
```

### ‚ùå Issues

1. **E2E Tests Don't Exist:** Mentioned but not implemented (no `*.e2e.ts` files found in codebase review)
2. **No Smoke Tests:** After deployment, no verification that app actually works
3. **No Deployment Approval:** Direct deploy to production without approval gate
4. **No Rollback Strategy:** If deployment fails, how to rollback?

### ‚úÖ Recommended GitHub Actions Workflow

```yaml
# .github/workflows/deploy-production.yml
name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:  # Manual trigger

env:
  AWS_REGION: us-east-1
  ECR_REPO: ratemyunit-api

jobs:
  # Stage 1: Quality Gates
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: pnpm/action-setup@v2
        with:
          version: 8

      - uses: actions/setup-node@v3
        with:
          node-version: 20
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Lint
        run: pnpm lint

      - name: Type check
        run: pnpm typecheck

      - name: Unit tests
        run: pnpm test

      - name: Build
        run: pnpm build

      - name: Security audit
        run: pnpm audit --production
        continue-on-error: true  # Don't block deploy, but log issues

  # Stage 2: Build & Push Docker Image
  build:
    needs: quality
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO }}
          tags: |
            type=sha,prefix=,suffix=,format=short
            type=raw,value=latest

      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Scan image with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.meta.outputs.tags }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  # Stage 3: Deploy (with approval gate)
  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://api.ratemyunit.com
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get EC2 instance ID
        id: get-instance
        run: |
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=ratemyunit-api" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].InstanceId" \
            --output text)
          echo "instance-id=$INSTANCE_ID" >> $GITHUB_OUTPUT

      - name: Deploy via SSM
        run: |
          aws ssm send-command \
            --instance-ids ${{ steps.get-instance.outputs.instance-id }} \
            --document-name "AWS-RunShellScript" \
            --parameters commands='[
              "cd /opt/ratemyunit",
              "export VERSION=${{ needs.build.outputs.image-tag }}",
              "docker-compose pull",
              "docker-compose up -d --no-deps api",
              "sleep 10",
              "curl -f http://localhost:3000/health || exit 1"
            ]' \
            --output text

  # Stage 4: Smoke Tests
  smoke-test:
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - name: Health check
        run: |
          curl -f https://api.ratemyunit.com/health || exit 1

      - name: Test search endpoint
        run: |
          RESPONSE=$(curl -s https://api.ratemyunit.com/api/units?search=test)
          echo $RESPONSE | jq -e '.success' || exit 1

      - name: Notify success
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Production deployment successful! :rocket:'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: success()

      - name: Notify failure & rollback
        if: failure()
        run: |
          echo "Smoke tests failed! Rolling back..."
          # Trigger rollback workflow
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/rollback.yml/dispatches \
            -d '{"ref":"main"}'
```

**Estimated Effort:** 12-16 hours

---

## Cross-Reference: Bug Fixes Required Before Production

**From `report/06-bug-detection-report.md`:**

### BLOCKER Bugs (Must fix before production):

1. **BUG-CRITICAL-001:** Race condition in browser instance sharing
   - **File:** `queue.ts:29-66`
   - **Fix:** Implement connection pooling with `generic-pool`
   - **Effort:** 12-16 hours

2. **BUG-CRITICAL-002:** Integer overflow in range generation
   - **File:** `template.ts:249-276`
   - **Fix:** Add MAX_SAFE_INTEGER validation
   - **Effort:** 2-4 hours

3. **BUG-CRITICAL-003:** Page not closed on exception
   - **File:** `courseloop.ts:102-136`
   - **Fix:** Add try/finally block
   - **Effort:** 2-3 hours

4. **BUG-CRITICAL-004:** Infinite backoff loop
   - **File:** `queue.ts:145-152`
   - **Fix:** Exponential backoff with max limit
   - **Effort:** 4-6 hours

5. **BUG-CRITICAL-005:** Job count not reset on browser failure
   - **File:** `queue.ts:164-166`
   - **Fix:** Proper error recovery
   - **Effort:** 3-4 hours

**Total Critical Bug Fix Effort:** 23-33 hours

---

## Deployment Readiness Scorecard

| Category | Grade | Blockers | High Priority | Total Issues |
|----------|-------|----------|---------------|--------------|
| Infrastructure | C+ | 4 | 3 | 15 |
| Application Security | C | 2 | 2 | 8 |
| Reliability | D+ | 3 | 2 | 12 |
| Monitoring | F | 1 | 1 | 5 |
| CI/CD | C | 0 | 2 | 6 |
| Documentation | D | 0 | 2 | 4 |
| **Overall** | **D+ (68/100)** | **10** | **12** | **50** |

---

## Pre-Production Checklist (Updated)

### Week 1 - Critical Blockers (Must Complete)

- [ ] **Fix BUG-CRITICAL-001:** Browser race condition (12-16h)
- [ ] **Fix BUG-CRITICAL-003:** Page leak on exception (2-3h)
- [ ] **Fix BUG-CRITICAL-004:** Infinite backoff loop (4-6h)
- [ ] **Implement Monitoring:** CloudWatch alarms for CPU, memory, status checks (4-6h)
- [ ] **Backup Strategy:** RDS automated backups + AMI snapshots (8-10h)
- [ ] **Load Testing:** Run k6 tests, establish baselines (8-12h)
- [ ] **Graceful Shutdown:** SIGTERM handling (4-6h)

**Total Effort:** 42-59 hours (~1-1.5 weeks)

### Week 2 - High Priority

- [ ] **Zero-Downtime Deploy:** Blue/green or rolling deployment (6-8h)
- [ ] **Fix Security Vulnerabilities:** ReDoS, XXE (12-16h)
- [ ] **Incident Response:** Write runbooks (12-16h)
- [ ] **Migration Strategy:** Rollback procedures (6-8h)
- [ ] **CI/CD Pipeline:** GitHub Actions with gates (12-16h)
- [ ] **User Data Script:** Idempotent + logging (4-6h)

**Total Effort:** 52-70 hours (~1.5-2 weeks)

### Week 3-4 - Medium Priority

- [ ] **Database Decoupling:** Remove DB access from scrapers (16-24h)
- [ ] **Performance Optimization:** DB connection pooling (4-6h)
- [ ] **SLO Definition:** Define and implement monitoring (4-6h)
- [ ] **Frontend Optimization:** Bundle size, performance budget (8-12h)
- [ ] **E2E Tests:** Implement smoke tests (12-16h)

**Total Effort:** 44-64 hours (~1-1.5 weeks)

---

## Recommended Production Timeline

```
Week 1-2:   Fix critical bugs + monitoring + load testing
            ‚îî‚îÄ Deploy to staging environment

Week 3-4:   Zero-downtime deploy + security fixes + CI/CD
            ‚îî‚îÄ Deploy to production with limited beta users

Week 5-6:   Performance optimization + E2E tests
            ‚îî‚îÄ Full production release

Week 7-8:   Database refactoring + architectural improvements
            ‚îî‚îÄ Enterprise-ready state
```

**Total Effort Before Production:** 138-193 hours (3.5-4.8 weeks)

**Current State:** NOT READY for production deployment

---

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| Browser memory leak causes OOM crash | **HIGH** | **CRITICAL** | Fix BUG-CRITICAL-001 before production |
| Deployment causes downtime | **MEDIUM** | **HIGH** | Implement blue/green deployment |
| Security breach (ReDoS/XXE) | **MEDIUM** | **CRITICAL** | Fix security vulnerabilities |
| Database migration breaks app | **LOW** | **CRITICAL** | Implement backward-compatible migrations |
| No monitoring, outage goes unnoticed | **HIGH** | **CRITICAL** | Implement CloudWatch alarms |
| Data loss (no backups) | **LOW** | **CRITICAL** | Enable RDS automated backups |
| Performance degradation under load | **MEDIUM** | **HIGH** | Perform load testing |

---

## Final Recommendations for Gemini

### Immediate Actions (Before ANY Production Deployment)

1. **DO NOT DEPLOY** current code to production - critical bugs present
2. **FIX CRITICAL BUGS** first (Week 1 checklist above)
3. **IMPLEMENT MONITORING** before deployment (you're flying blind without it)
4. **LOAD TEST** in staging environment with production-like data
5. **ESTABLISH BACKUPS** and test restoration procedures

### Short-Term Improvements (Pre-Production)

1. Zero-downtime deployment strategy
2. Security vulnerability fixes (ReDoS, XXE)
3. Incident response runbooks
4. CI/CD pipeline with automated testing and approval gates
5. Graceful shutdown handling

### Long-Term Architecture (Post-Production)

1. Decouple database access from scrapers
2. Migrate to ECS Fargate for better scalability
3. Implement blue/green deployment at infrastructure level
4. Add comprehensive E2E testing
5. Performance optimization (connection pooling, caching)

### Estimated Timeline to Production-Ready

- **Minimum (with shortcuts):** 3-4 weeks
- **Recommended (proper fixes):** 6-8 weeks
- **Enterprise-grade:** 10-12 weeks

---

## Conclusion

The deployment plan demonstrates good understanding of AWS Free Tier optimization and basic infrastructure setup, but **lacks critical production requirements** including monitoring, disaster recovery, incident response, and load testing.

The production readiness checklist covers good security and containerization practices, but **misses critical cross-references** to the 37 bugs and 23 security vulnerabilities identified in previous audit reports.

**Current Deployment Readiness:** **68/100 (D+)** - **NOT READY for production**

**After implementing Week 1-2 fixes:** **82/100 (B-)** - **Acceptable for limited beta**

**After implementing all recommendations:** **92/100 (A-)** - **Production-ready**

---

*Generated by Senior DevOps/SRE Engineer*
*Review Date: January 29, 2026*
*Cross-Referenced: Architecture, Security, Performance, Bug Detection Reports*
